{"cells": [{"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": "from codetf.trainer.codet5_trainer import CodeT5Seq2SeqTrainer\nfrom codetf.data_utility.codexglue_dataset import CodeXGLUEDataset\nfrom codetf.models import load_model_pipeline\nfrom codetf.performance.evaluation_metric import EvaluationMetric\nfrom codetf.data_utility.base_dataset import CustomDataset\n\nmodel_class = load_model_pipeline(model_name=\"codet5\", task=\"pretrained\",\n            model_type=\"plus-770M-python\", is_eval=True)\n\ndataset = CodeXGLUEDataset(tokenizer=model_class.get_tokenizer())\ntrain, test, validation = dataset.load(\"code-to-text\", \"python\")\n\ntrain_dataset= CustomDataset(train[0], train[1])\ntest_dataset= CustomDataset(test[0], test[1])\nval_dataset= CustomDataset(validation[0], validation[1])\n\nevaluator = EvaluationMetric(metric=\"bleu\", tokenizer=model_class.tokenizer)\n\ntrainer = CodeT5Seq2SeqTrainer(train_dataset=train_dataset, \n                                validation_dataset=val_dataset, \n                                peft=\"lora\",\n                                pretrained_model_or_path=model_class.get_model(),\n                                tokenizer=model_class.tokenizer)\ntrainer.train()"}], "metadata": {"kernelspec": {"display_name": "tf", "language": "python", "name": "python3"}, "language_info": {"codemirror_mode": {"name": "ipython", "version": 3}, "file_extension": ".py", "mimetype": "text/x-python", "name": "python", "nbconvert_exporter": "python", "pygments_lexer": "ipython3", "version": "3.10.11"}, "orig_nbformat": 4}, "nbformat": 4, "nbformat_minor": 2}