{"cells": [{"cell_type": "code", "execution_count": 1, "metadata": {}, "outputs": [{"name": "stderr", "output_type": "stream", "text": ["/home/paul/.conda/envs/codetf/lib/python3.10/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n", "  from .autonotebook import tqdm as notebook_tqdm\n"]}], "source": "from abc import ABC\nfrom pathlib import Path\n\nimport pandas as pd\nfrom codetf.models import load_model_pipeline\nfrom rouge_score import rouge_scorer\nfrom nltk.translate.meteor_score import meteor_score\nfrom sacrebleu import corpus_bleu, corpus_chrf, corpus_ter\nfrom datasets import load_dataset\nfrom transformers import AutoTokenizer, AutoModelWithLMHead, SummarizationPipeline"}, {"cell_type": "code", "execution_count": 2, "metadata": {}, "outputs": [], "source": "root_dir = Path.cwd()"}, {"attachments": {}, "cell_type": "markdown", "metadata": {}, "source": ["# Create Predictions\n", "Im folgenden wird mit allen Models f\u00fcr den Testdatensatz die Predictions generiert."]}, {"cell_type": "code", "execution_count": 3, "metadata": {}, "outputs": [], "source": "class AbstractModel(ABC):\n    def predict(self, code: str) -> str:\n        \"\"\"Predicts the given code .\"\"\"\n        raise NotImplementedError()\n    \n    def model_name(self) -> str:\n        \"\"\"Returns the model name .\"\"\"\n        raise NotImplementedError()\n    \nclass CodeTFModel(AbstractModel):\n    def __init__(self, model_name: str, model_type: str, task: str) -> None:\n        \"\"\"Initialize the pipeline .\"\"\"\n        super().__init__()\n\n        self._model = load_model_pipeline(model_name=model_name, model_type=model_type, task=task)\n        self._model_name = model_name\n        self._model_type = model_type\n        self._task = task\n\n    def predict(self, code: str) -> str:\n        \"\"\"Predicts the given code .\"\"\"\n        return self._model.predict([code])[0]\n    \n    def model_name(self) -> str:\n        \"\"\"The name of the model .\"\"\"\n        return f\"{self._model_name}-{self._model_type}-{self._task}\"\n    \nclass SebisModel(AbstractModel):\n    def __init__(self, model_name: str) -> None:\n        \"\"\"Initialize the pipeline .\"\"\"\n        super().__init__()\n\n        self._pipeline = SummarizationPipeline(\n            model=AutoModelWithLMHead.from_pretrained(model_name),\n            tokenizer=AutoTokenizer.from_pretrained(model_name, skip_special_tokens=True),\n            device=0\n        )\n        self._model_name = model_name\n\n    def predict(self, code: str) -> str:\n        \"\"\"Predict the text for a given code .\"\"\"\n        return self._pipeline([code])[0][\"summary_text\"]\n    \n    def model_name(self) -> str:\n        \"\"\"The model name of the model .\"\"\"\n        return self._model_name.replace(\"/\", \"-\")"}, {"cell_type": "code", "execution_count": 4, "metadata": {}, "outputs": [], "source": "def get_preds(df: pd.DataFrame, model: AbstractModel):\n    \"\"\"Get predictions from a model .\"\"\"\n    file_path = root_dir / \"data\" / \"preds\" / f\"{model.model_name()}.csv\"\n    \n    if file_path.exists():\n        return\n\n    df = df.copy()\n    df[\"pred\"] = df[\"code\"].map(model.predict)\n    df[[\"ref\", \"pred\"]].to_csv(file_path)"}, {"cell_type": "code", "execution_count": 5, "metadata": {}, "outputs": [{"name": "stderr", "output_type": "stream", "text": ["Found cached dataset json (/home/paul/projects/edu/master/mdl-ii/src/data/cache/json/default-acdd91729f392843/0.0.0/e347ab1c932092252e717ff3f949105a4dd28b27e842dd53157d2f72e276c2e4)\n", "100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 1/1 [00:00<00:00, 17.64it/s]\n"]}], "source": "dataset = load_dataset(\"json\", data_files={\n    \"test\": str(root_dir.parent / \"data\" / \"test.jsonl\"),\n}, cache_dir=root_dir.parent / \"data\" / \"cache\")"}, {"cell_type": "code", "execution_count": 6, "metadata": {}, "outputs": [{"name": "stderr", "output_type": "stream", "text": ["Loading cached processed dataset at /home/paul/projects/edu/master/mdl-ii/src/data/cache/json/default-acdd91729f392843/0.0.0/e347ab1c932092252e717ff3f949105a4dd28b27e842dd53157d2f72e276c2e4/cache-e06db1d51f6ed421.arrow\n"]}, {"data": {"text/html": ["<div>\n", "<style scoped>\n", "    .dataframe tbody tr th:only-of-type {\n", "        vertical-align: middle;\n", "    }\n", "\n", "    .dataframe tbody tr th {\n", "        vertical-align: top;\n", "    }\n", "\n", "    .dataframe thead th {\n", "        text-align: right;\n", "    }\n", "</style>\n", "<table border=\"1\" class=\"dataframe\">\n", "  <thead>\n", "    <tr style=\"text-align: right;\">\n", "      <th></th>\n", "      <th>code</th>\n", "      <th>ref</th>\n", "    </tr>\n", "  </thead>\n", "  <tbody>\n", "    <tr>\n", "      <th>0</th>\n", "      <td>def sina_xml_to_url_list(xml_data):\\n    rawur...</td>\n", "      <td>str - &gt; list Convert XML to URL List . From Bi...</td>\n", "    </tr>\n", "    <tr>\n", "      <th>1</th>\n", "      <td>def dailymotion_download(url, output_dir='.', ...</td>\n", "      <td>Downloads Dailymotion videos by URL .</td>\n", "    </tr>\n", "    <tr>\n", "      <th>2</th>\n", "      <td>def sina_download(url, output_dir='.', merge=T...</td>\n", "      <td>Downloads Sina videos by URL .</td>\n", "    </tr>\n", "    <tr>\n", "      <th>3</th>\n", "      <td>def sprint(text, *colors):\\n    return \"\\33[{}...</td>\n", "      <td>Format text with color or other effects into A...</td>\n", "    </tr>\n", "    <tr>\n", "      <th>4</th>\n", "      <td>def print_log(text, *colors):\\n    sys.stderr....</td>\n", "      <td>Print a log message to standard error .</td>\n", "    </tr>\n", "  </tbody>\n", "</table>\n", "</div>"], "text/plain": ["                                                code  \\\n", "0  def sina_xml_to_url_list(xml_data):\\n    rawur...   \n", "1  def dailymotion_download(url, output_dir='.', ...   \n", "2  def sina_download(url, output_dir='.', merge=T...   \n", "3  def sprint(text, *colors):\\n    return \"\\33[{}...   \n", "4  def print_log(text, *colors):\\n    sys.stderr....   \n", "\n", "                                                 ref  \n", "0  str - > list Convert XML to URL List . From Bi...  \n", "1              Downloads Dailymotion videos by URL .  \n", "2                     Downloads Sina videos by URL .  \n", "3  Format text with color or other effects into A...  \n", "4            Print a log message to standard error .  "]}, "execution_count": 6, "metadata": {}, "output_type": "execute_result"}], "source": "def inference(doc):\n    \"\"\"Add the ref to the doc .\"\"\"\n    doc[\"ref\"] = [\" \".join(docstring) for docstring in doc[\"docstring_tokens\"]]\n    return doc    \n\ndataset = dataset.map(inference, batched=True)\ndataset.set_format(type=\"pandas\", columns=[\"ref\", \"code\"])\ndf = dataset[\"test\"][:]\ndf.head()"}, {"attachments": {}, "cell_type": "markdown", "metadata": {}, "source": ["## CodeT5 Base"]}, {"cell_type": "code", "execution_count": 7, "metadata": {}, "outputs": [], "source": "get_preds(df, CodeTFModel(model_name=\"codet5\", model_type=\"base-multi-sum\", task=\"pretrained\"))"}, {"cell_type": "code", "execution_count": 8, "metadata": {}, "outputs": [], "source": "get_preds(df, CodeTFModel(model_name=\"codet5\", model_type=\"base\", task=\"sum_python\"))"}, {"attachments": {}, "cell_type": "markdown", "metadata": {}, "source": ["## T5 Small"]}, {"cell_type": "code", "execution_count": 11, "metadata": {}, "outputs": [], "source": "get_preds(df, SebisModel(\"SEBIS/code_trans_t5_small_code_documentation_generation_python\"))"}, {"cell_type": "code", "execution_count": 12, "metadata": {}, "outputs": [], "source": "get_preds(df, SebisModel(\"SEBIS/code_trans_t5_small_code_documentation_generation_python_transfer_learning_finetune\"))"}, {"cell_type": "code", "execution_count": 13, "metadata": {}, "outputs": [], "source": "get_preds(df, SebisModel(\"SEBIS/code_trans_t5_small_code_documentation_generation_python_multitask\"))"}, {"cell_type": "code", "execution_count": 14, "metadata": {}, "outputs": [], "source": "get_preds(df, SebisModel(\"SEBIS/code_trans_t5_small_code_documentation_generation_python_multitask_finetune\"))"}, {"attachments": {}, "cell_type": "markdown", "metadata": {}, "source": ["## T5 Base"]}, {"cell_type": "code", "execution_count": 15, "metadata": {}, "outputs": [], "source": "get_preds(df, SebisModel(\"SEBIS/code_trans_t5_base_code_documentation_generation_python\"))"}, {"cell_type": "code", "execution_count": 16, "metadata": {}, "outputs": [], "source": "get_preds(df, SebisModel(\"SEBIS/code_trans_t5_base_code_documentation_generation_python_transfer_learning_finetune\"))"}, {"cell_type": "code", "execution_count": 17, "metadata": {}, "outputs": [], "source": "get_preds(df, SebisModel(\"SEBIS/code_trans_t5_base_code_documentation_generation_python_multitask\"))"}, {"cell_type": "code", "execution_count": 18, "metadata": {}, "outputs": [], "source": "get_preds(df, SebisModel(\"SEBIS/code_trans_t5_base_code_documentation_generation_python_multitask_finetune\"))"}, {"attachments": {}, "cell_type": "markdown", "metadata": {}, "source": ["## T5 Large"]}, {"cell_type": "code", "execution_count": 7, "metadata": {}, "outputs": [{"name": "stderr", "output_type": "stream", "text": ["/home/paul/.conda/envs/codetf/lib/python3.10/site-packages/transformers/models/auto/modeling_auto.py:1363: FutureWarning: The class `AutoModelWithLMHead` is deprecated and will be removed in a future version. Please use `AutoModelForCausalLM` for causal language models, `AutoModelForMaskedLM` for masked language models and `AutoModelForSeq2SeqLM` for encoder-decoder models.\n", "  warnings.warn(\n"]}], "source": "get_preds(df, SebisModel(\"SEBIS/code_trans_t5_large_code_documentation_generation_python_transfer_learning_finetune\"))"}, {"cell_type": "code", "execution_count": 8, "metadata": {}, "outputs": [], "source": "get_preds(df, SebisModel(\"SEBIS/code_trans_t5_large_code_documentation_generation_python_multitask\"))"}, {"cell_type": "code", "execution_count": 9, "metadata": {}, "outputs": [], "source": "get_preds(df, SebisModel(\"SEBIS/code_trans_t5_large_code_documentation_generation_python_multitask_finetune\"))"}, {"attachments": {}, "cell_type": "markdown", "metadata": {}, "source": ["# Auswertung"]}, {"cell_type": "code", "execution_count": 3, "metadata": {}, "outputs": [], "source": "def get_scores(df: pd.DataFrame, model_name: str):\n    \"\"\"Get scores for a given model .\"\"\"\n    scorer = rouge_scorer.RougeScorer([\"rouge1\", \"rougeL\"], use_stemmer=True)\n    scores = [scorer.score(ref, hyp) for ref, hyp in zip(df[\"ref\"].to_list(), df[\"pred\"].to_list())]\n    rouge1 = sum([score[\"rouge1\"].fmeasure for score in scores]) / len(scores)\n    rougeL = sum([score[\"rougeL\"].fmeasure for score in scores]) / len(scores)\n    # meteor = sum([meteor_score([ref], hyp) for ref, hyp in zip(df[\"ref\"].to_list(), df[\"pred\"].to_list())]) / len(df[\"pred\"].to_list())\n\n    return pd.DataFrame({\n        \"bleu\": corpus_bleu(df[\"pred\"].to_list(), [df[\"ref\"].to_list()]).score,\n        \"chrf\": corpus_chrf(df[\"pred\"].to_list(), [df[\"ref\"].to_list()]).score,\n        \"ter\": corpus_ter(df[\"pred\"].to_list(), [df[\"ref\"].to_list()]).score,\n        \"rouge1\": rouge1, \"rougeL\": rougeL\n    }, index=pd.Index([model_name], name=\"Model\"))"}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": "df = pd.DataFrame(columns=[\"bleu\", \"chrf\", \"ter\"])\n\nfor csv_file in sorted((root_dir / \"data\" / \"preds\").glob(\"*.csv\"), key=lambda f: f.name):\n    df = pd.concat([df, get_scores(pd.read_csv(csv_file, index_col=0), csv_file.name)])"}, {"cell_type": "code", "execution_count": 5, "metadata": {}, "outputs": [{"data": {"text/html": ["<div>\n", "<style scoped>\n", "    .dataframe tbody tr th:only-of-type {\n", "        vertical-align: middle;\n", "    }\n", "\n", "    .dataframe tbody tr th {\n", "        vertical-align: top;\n", "    }\n", "\n", "    .dataframe thead th {\n", "        text-align: right;\n", "    }\n", "</style>\n", "<table border=\"1\" class=\"dataframe\">\n", "  <thead>\n", "    <tr style=\"text-align: right;\">\n", "      <th></th>\n", "      <th>bleu</th>\n", "      <th>chrf</th>\n", "      <th>ter</th>\n", "      <th>rouge1</th>\n", "      <th>rougeL</th>\n", "    </tr>\n", "  </thead>\n", "  <tbody>\n", "    <tr>\n", "      <th>SEBIS-code_trans_t5_base_code_documentation_generation_python.csv</th>\n", "      <td>4.638</td>\n", "      <td>23.194</td>\n", "      <td>102.021</td>\n", "      <td>0.263</td>\n", "      <td>0.234</td>\n", "    </tr>\n", "    <tr>\n", "      <th>SEBIS-code_trans_t5_base_code_documentation_generation_python_multitask.csv</th>\n", "      <td>2.957</td>\n", "      <td>15.566</td>\n", "      <td>93.160</td>\n", "      <td>0.221</td>\n", "      <td>0.208</td>\n", "    </tr>\n", "    <tr>\n", "      <th>SEBIS-code_trans_t5_base_code_documentation_generation_python_multitask_finetune.csv</th>\n", "      <td>13.766</td>\n", "      <td>33.452</td>\n", "      <td>78.742</td>\n", "      <td>0.443</td>\n", "      <td>0.410</td>\n", "    </tr>\n", "    <tr>\n", "      <th>SEBIS-code_trans_t5_base_code_documentation_generation_python_transfer_learning_finetune.csv</th>\n", "      <td>21.671</td>\n", "      <td>37.954</td>\n", "      <td>71.560</td>\n", "      <td>0.485</td>\n", "      <td>0.457</td>\n", "    </tr>\n", "    <tr>\n", "      <th>SEBIS-code_trans_t5_large_code_documentation_generation_python_multitask.csv</th>\n", "      <td>13.487</td>\n", "      <td>32.527</td>\n", "      <td>79.615</td>\n", "      <td>0.433</td>\n", "      <td>0.401</td>\n", "    </tr>\n", "    <tr>\n", "      <th>SEBIS-code_trans_t5_large_code_documentation_generation_python_multitask_finetune.csv</th>\n", "      <td>16.362</td>\n", "      <td>35.033</td>\n", "      <td>80.671</td>\n", "      <td>0.445</td>\n", "      <td>0.412</td>\n", "    </tr>\n", "    <tr>\n", "      <th>SEBIS-code_trans_t5_large_code_documentation_generation_python_transfer_learning_finetune.csv</th>\n", "      <td>23.306</td>\n", "      <td>38.984</td>\n", "      <td>69.745</td>\n", "      <td>0.497</td>\n", "      <td>0.470</td>\n", "    </tr>\n", "    <tr>\n", "      <th>SEBIS-code_trans_t5_small_code_documentation_generation_python.csv</th>\n", "      <td>5.495</td>\n", "      <td>25.007</td>\n", "      <td>103.981</td>\n", "      <td>0.287</td>\n", "      <td>0.256</td>\n", "    </tr>\n", "    <tr>\n", "      <th>SEBIS-code_trans_t5_small_code_documentation_generation_python_multitask.csv</th>\n", "      <td>5.450</td>\n", "      <td>20.280</td>\n", "      <td>89.910</td>\n", "      <td>0.295</td>\n", "      <td>0.276</td>\n", "    </tr>\n", "    <tr>\n", "      <th>SEBIS-code_trans_t5_small_code_documentation_generation_python_multitask_finetune.csv</th>\n", "      <td>16.378</td>\n", "      <td>34.692</td>\n", "      <td>76.738</td>\n", "      <td>0.452</td>\n", "      <td>0.421</td>\n", "    </tr>\n", "    <tr>\n", "      <th>SEBIS-code_trans_t5_small_code_documentation_generation_python_transfer_learning_finetune.csv</th>\n", "      <td>21.093</td>\n", "      <td>37.157</td>\n", "      <td>71.626</td>\n", "      <td>0.476</td>\n", "      <td>0.448</td>\n", "    </tr>\n", "    <tr>\n", "      <th>codet5-base-multi-sum-pretrained.csv</th>\n", "      <td>23.564</td>\n", "      <td>39.069</td>\n", "      <td>93.313</td>\n", "      <td>0.489</td>\n", "      <td>0.462</td>\n", "    </tr>\n", "    <tr>\n", "      <th>codet5-base-sum_python.csv</th>\n", "      <td>23.985</td>\n", "      <td>39.318</td>\n", "      <td>88.667</td>\n", "      <td>0.491</td>\n", "      <td>0.463</td>\n", "    </tr>\n", "    <tr>\n", "      <th>codet5p_220m.csv</th>\n", "      <td>25.245</td>\n", "      <td>40.596</td>\n", "      <td>66.514</td>\n", "      <td>0.515</td>\n", "      <td>0.488</td>\n", "    </tr>\n", "  </tbody>\n", "</table>\n", "</div>"], "text/plain": ["                                                     bleu   chrf     ter  \\\n", "SEBIS-code_trans_t5_base_code_documentation_gen...  4.638 23.194 102.021   \n", "SEBIS-code_trans_t5_base_code_documentation_gen...  2.957 15.566  93.160   \n", "SEBIS-code_trans_t5_base_code_documentation_gen... 13.766 33.452  78.742   \n", "SEBIS-code_trans_t5_base_code_documentation_gen... 21.671 37.954  71.560   \n", "SEBIS-code_trans_t5_large_code_documentation_ge... 13.487 32.527  79.615   \n", "SEBIS-code_trans_t5_large_code_documentation_ge... 16.362 35.033  80.671   \n", "SEBIS-code_trans_t5_large_code_documentation_ge... 23.306 38.984  69.745   \n", "SEBIS-code_trans_t5_small_code_documentation_ge...  5.495 25.007 103.981   \n", "SEBIS-code_trans_t5_small_code_documentation_ge...  5.450 20.280  89.910   \n", "SEBIS-code_trans_t5_small_code_documentation_ge... 16.378 34.692  76.738   \n", "SEBIS-code_trans_t5_small_code_documentation_ge... 21.093 37.157  71.626   \n", "codet5-base-multi-sum-pretrained.csv               23.564 39.069  93.313   \n", "codet5-base-sum_python.csv                         23.985 39.318  88.667   \n", "codet5p_220m.csv                                   25.245 40.596  66.514   \n", "\n", "                                                    rouge1  rougeL  \n", "SEBIS-code_trans_t5_base_code_documentation_gen...   0.263   0.234  \n", "SEBIS-code_trans_t5_base_code_documentation_gen...   0.221   0.208  \n", "SEBIS-code_trans_t5_base_code_documentation_gen...   0.443   0.410  \n", "SEBIS-code_trans_t5_base_code_documentation_gen...   0.485   0.457  \n", "SEBIS-code_trans_t5_large_code_documentation_ge...   0.433   0.401  \n", "SEBIS-code_trans_t5_large_code_documentation_ge...   0.445   0.412  \n", "SEBIS-code_trans_t5_large_code_documentation_ge...   0.497   0.470  \n", "SEBIS-code_trans_t5_small_code_documentation_ge...   0.287   0.256  \n", "SEBIS-code_trans_t5_small_code_documentation_ge...   0.295   0.276  \n", "SEBIS-code_trans_t5_small_code_documentation_ge...   0.452   0.421  \n", "SEBIS-code_trans_t5_small_code_documentation_ge...   0.476   0.448  \n", "codet5-base-multi-sum-pretrained.csv                 0.489   0.462  \n", "codet5-base-sum_python.csv                           0.491   0.463  \n", "codet5p_220m.csv                                     0.515   0.488  "]}, "execution_count": 5, "metadata": {}, "output_type": "execute_result"}], "source": "pd.options.display.float_format = '{:.3f}'.format\ndf"}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ""}], "metadata": {"kernelspec": {"display_name": "codetf", "language": "python", "name": "python3"}, "language_info": {"codemirror_mode": {"name": "ipython", "version": 3}, "file_extension": ".py", "mimetype": "text/x-python", "name": "python", "nbconvert_exporter": "python", "pygments_lexer": "ipython3", "version": "3.10.11"}, "orig_nbformat": 4}, "nbformat": 4, "nbformat_minor": 2}