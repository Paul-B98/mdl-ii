{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/paul/.conda/envs/codetf/lib/python3.10/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from abc import ABC\n",
    "from pathlib import Path\n",
    "\n",
    "import pandas as pd\n",
    "from codetf.models import load_model_pipeline\n",
    "from rouge_score import rouge_scorer\n",
    "from nltk.translate.meteor_score import meteor_score\n",
    "from sacrebleu import corpus_bleu, corpus_chrf, corpus_ter\n",
    "from datasets import load_dataset\n",
    "from transformers import AutoTokenizer, AutoModelWithLMHead, SummarizationPipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "root_dir = Path.cwd()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create Predictions\n",
    "Im folgenden wird mit allen Models für den Testdatensatz die Predictions generiert."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AbstractModel(ABC):\n",
    "    def predict(self, code: str) -> str:\n",
    "        raise NotImplementedError()\n",
    "    \n",
    "    def model_name(self) -> str:\n",
    "        raise NotImplementedError()\n",
    "    \n",
    "class CodeTFModel(AbstractModel):\n",
    "    def __init__(self, model_name: str, model_type: str, task: str) -> None:\n",
    "        super().__init__()\n",
    "\n",
    "        self._model = load_model_pipeline(model_name=model_name, model_type=model_type, task=task)\n",
    "        self._model_name = model_name\n",
    "        self._model_type = model_type\n",
    "        self._task = task\n",
    "\n",
    "    def predict(self, code: str) -> str:\n",
    "        return self._model.predict([code])[0]\n",
    "    \n",
    "    def model_name(self) -> str:\n",
    "        return f\"{self._model_name}-{self._model_type}-{self._task}\"\n",
    "    \n",
    "class SebisModel(AbstractModel):\n",
    "    def __init__(self, model_name: str) -> None:\n",
    "        super().__init__()\n",
    "\n",
    "        self._pipeline = SummarizationPipeline(\n",
    "            model=AutoModelWithLMHead.from_pretrained(model_name),\n",
    "            tokenizer=AutoTokenizer.from_pretrained(model_name, skip_special_tokens=True),\n",
    "            device=0\n",
    "        )\n",
    "        self._model_name = model_name\n",
    "\n",
    "    def predict(self, code: str) -> str:\n",
    "        return self._pipeline([code])[0][\"summary_text\"]\n",
    "    \n",
    "    def model_name(self) -> str:\n",
    "        return self._model_name.replace(\"/\", \"-\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_preds(df: pd.DataFrame, model: AbstractModel):\n",
    "    file_path = root_dir / \"data\" / \"preds\" / f\"{model.model_name()}.csv\"\n",
    "    \n",
    "    if file_path.exists():\n",
    "        return\n",
    "\n",
    "    df = df.copy()\n",
    "    df[\"pred\"] = df[\"code\"].map(model.predict)\n",
    "    df[[\"ref\", \"pred\"]].to_csv(file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found cached dataset json (/home/paul/projects/edu/master/mdl-ii/src/data/cache/json/default-acdd91729f392843/0.0.0/e347ab1c932092252e717ff3f949105a4dd28b27e842dd53157d2f72e276c2e4)\n",
      "100%|██████████| 1/1 [00:00<00:00, 17.64it/s]\n"
     ]
    }
   ],
   "source": [
    "dataset = load_dataset(\"json\", data_files={\n",
    "    \"test\": str(root_dir.parent / \"data\" / \"test.jsonl\"),\n",
    "}, cache_dir=root_dir.parent / \"data\" / \"cache\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at /home/paul/projects/edu/master/mdl-ii/src/data/cache/json/default-acdd91729f392843/0.0.0/e347ab1c932092252e717ff3f949105a4dd28b27e842dd53157d2f72e276c2e4/cache-e06db1d51f6ed421.arrow\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>code</th>\n",
       "      <th>ref</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>def sina_xml_to_url_list(xml_data):\\n    rawur...</td>\n",
       "      <td>str - &gt; list Convert XML to URL List . From Bi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>def dailymotion_download(url, output_dir='.', ...</td>\n",
       "      <td>Downloads Dailymotion videos by URL .</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>def sina_download(url, output_dir='.', merge=T...</td>\n",
       "      <td>Downloads Sina videos by URL .</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>def sprint(text, *colors):\\n    return \"\\33[{}...</td>\n",
       "      <td>Format text with color or other effects into A...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>def print_log(text, *colors):\\n    sys.stderr....</td>\n",
       "      <td>Print a log message to standard error .</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                code  \\\n",
       "0  def sina_xml_to_url_list(xml_data):\\n    rawur...   \n",
       "1  def dailymotion_download(url, output_dir='.', ...   \n",
       "2  def sina_download(url, output_dir='.', merge=T...   \n",
       "3  def sprint(text, *colors):\\n    return \"\\33[{}...   \n",
       "4  def print_log(text, *colors):\\n    sys.stderr....   \n",
       "\n",
       "                                                 ref  \n",
       "0  str - > list Convert XML to URL List . From Bi...  \n",
       "1              Downloads Dailymotion videos by URL .  \n",
       "2                     Downloads Sina videos by URL .  \n",
       "3  Format text with color or other effects into A...  \n",
       "4            Print a log message to standard error .  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def inference(doc):\n",
    "    doc[\"ref\"] = [\" \".join(docstring) for docstring in doc[\"docstring_tokens\"]]\n",
    "    return doc    \n",
    "\n",
    "dataset = dataset.map(inference, batched=True)\n",
    "dataset.set_format(type=\"pandas\", columns=[\"ref\", \"code\"])\n",
    "df = dataset[\"test\"][:]\n",
    "df.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CodeT5 Base"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_preds(df, CodeTFModel(model_name=\"codet5\", model_type=\"base-multi-sum\", task=\"pretrained\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_preds(df, CodeTFModel(model_name=\"codet5\", model_type=\"base\", task=\"sum_python\"))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## T5 Small"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_preds(df, SebisModel(\"SEBIS/code_trans_t5_small_code_documentation_generation_python\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_preds(df, SebisModel(\"SEBIS/code_trans_t5_small_code_documentation_generation_python_transfer_learning_finetune\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_preds(df, SebisModel(\"SEBIS/code_trans_t5_small_code_documentation_generation_python_multitask\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_preds(df, SebisModel(\"SEBIS/code_trans_t5_small_code_documentation_generation_python_multitask_finetune\"))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## T5 Base"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_preds(df, SebisModel(\"SEBIS/code_trans_t5_base_code_documentation_generation_python\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_preds(df, SebisModel(\"SEBIS/code_trans_t5_base_code_documentation_generation_python_transfer_learning_finetune\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_preds(df, SebisModel(\"SEBIS/code_trans_t5_base_code_documentation_generation_python_multitask\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_preds(df, SebisModel(\"SEBIS/code_trans_t5_base_code_documentation_generation_python_multitask_finetune\"))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## T5 Large"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/paul/.conda/envs/codetf/lib/python3.10/site-packages/transformers/models/auto/modeling_auto.py:1363: FutureWarning: The class `AutoModelWithLMHead` is deprecated and will be removed in a future version. Please use `AutoModelForCausalLM` for causal language models, `AutoModelForMaskedLM` for masked language models and `AutoModelForSeq2SeqLM` for encoder-decoder models.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "get_preds(df, SebisModel(\"SEBIS/code_trans_t5_large_code_documentation_generation_python_transfer_learning_finetune\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_preds(df, SebisModel(\"SEBIS/code_trans_t5_large_code_documentation_generation_python_multitask\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_preds(df, SebisModel(\"SEBIS/code_trans_t5_large_code_documentation_generation_python_multitask_finetune\"))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Auswertung"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_scores(df: pd.DataFrame, model_name: str):\n",
    "    scorer = rouge_scorer.RougeScorer([\"rouge1\", \"rougeL\"], use_stemmer=True)\n",
    "    scores = [scorer.score(ref, hyp) for ref, hyp in zip(df[\"ref\"].to_list(), df[\"pred\"].to_list())]\n",
    "    rouge1 = sum([score[\"rouge1\"].fmeasure for score in scores]) / len(scores)\n",
    "    rougeL = sum([score[\"rougeL\"].fmeasure for score in scores]) / len(scores)\n",
    "    # meteor = sum([meteor_score([ref], hyp) for ref, hyp in zip(df[\"ref\"].to_list(), df[\"pred\"].to_list())]) / len(df[\"pred\"].to_list())\n",
    "\n",
    "    return pd.DataFrame({\n",
    "        \"bleu\": corpus_bleu(df[\"pred\"].to_list(), [df[\"ref\"].to_list()]).score,\n",
    "        \"chrf\": corpus_chrf(df[\"pred\"].to_list(), [df[\"ref\"].to_list()]).score,\n",
    "        \"ter\": corpus_ter(df[\"pred\"].to_list(), [df[\"ref\"].to_list()]).score,\n",
    "        \"rouge1\": rouge1, \"rougeL\": rougeL\n",
    "    }, index=pd.Index([model_name], name=\"Model\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>bleu</th>\n",
       "      <th>chrf</th>\n",
       "      <th>ter</th>\n",
       "      <th>rouge1</th>\n",
       "      <th>rougeL</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>SEBIS-code_trans_t5_large_code_documentation_generation_python_multitask.csv</th>\n",
       "      <td>7.233727</td>\n",
       "      <td>35.369698</td>\n",
       "      <td>104.109589</td>\n",
       "      <td>0.383260</td>\n",
       "      <td>0.361623</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SEBIS-code_trans_t5_large_code_documentation_generation_python_multitask_finetune.csv</th>\n",
       "      <td>1.247227</td>\n",
       "      <td>27.547271</td>\n",
       "      <td>87.671233</td>\n",
       "      <td>0.353889</td>\n",
       "      <td>0.342778</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SEBIS-code_trans_t5_large_code_documentation_generation_python_transfer_learning_finetune.csv</th>\n",
       "      <td>8.862054</td>\n",
       "      <td>35.338268</td>\n",
       "      <td>83.561644</td>\n",
       "      <td>0.420366</td>\n",
       "      <td>0.409255</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                        bleu       chrf  \\\n",
       "SEBIS-code_trans_t5_large_code_documentation_ge...  7.233727  35.369698   \n",
       "SEBIS-code_trans_t5_large_code_documentation_ge...  1.247227  27.547271   \n",
       "SEBIS-code_trans_t5_large_code_documentation_ge...  8.862054  35.338268   \n",
       "\n",
       "                                                           ter    rouge1  \\\n",
       "SEBIS-code_trans_t5_large_code_documentation_ge...  104.109589  0.383260   \n",
       "SEBIS-code_trans_t5_large_code_documentation_ge...   87.671233  0.353889   \n",
       "SEBIS-code_trans_t5_large_code_documentation_ge...   83.561644  0.420366   \n",
       "\n",
       "                                                      rougeL  \n",
       "SEBIS-code_trans_t5_large_code_documentation_ge...  0.361623  \n",
       "SEBIS-code_trans_t5_large_code_documentation_ge...  0.342778  \n",
       "SEBIS-code_trans_t5_large_code_documentation_ge...  0.409255  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame(columns=[\"bleu\", \"chrf\", \"ter\"])\n",
    "\n",
    "for csv_file in sorted((root_dir / \"data\" / \"preds\").glob(\"*.csv\"), key=lambda f: f.name):\n",
    "    df = pd.concat([df, get_scores(pd.read_csv(csv_file, index_col=0), csv_file.name)])\n",
    "\n",
    "df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "codetf",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
