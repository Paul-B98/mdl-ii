{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "gather": {
          "logged": 1688125156878
        }
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/anaconda/envs/codetf/lib/python3.10/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
            "  from .autonotebook import tqdm as notebook_tqdm\n",
            "/anaconda/envs/codetf/lib/python3.10/site-packages/bitsandbytes/cuda_setup/main.py:149: UserWarning: WARNING: The following directories listed in your path were found to be non-existent: {PosixPath('//eastus.api.azureml.ms/mlflow/v1.0/subscriptions/60089760-5d77-4a24-b1f4-03f3eb78acf6/resourceGroups/azure-test-resource-group/providers/Microsoft.MachineLearningServices/workspaces/mdl'), PosixPath('azureml')}\n",
            "  warn(msg)\n",
            "/anaconda/envs/codetf/lib/python3.10/site-packages/bitsandbytes/cuda_setup/main.py:149: UserWarning: WARNING: The following directories listed in your path were found to be non-existent: {PosixPath('//127.0.0.1'), PosixPath('http'), PosixPath('46808/OBO/token')}\n",
            "  warn(msg)\n",
            "/anaconda/envs/codetf/lib/python3.10/site-packages/bitsandbytes/cuda_setup/main.py:149: UserWarning: WARNING: The following directories listed in your path were found to be non-existent: {PosixPath('//127.0.0.1'), PosixPath('46808/MSI/auth'), PosixPath('http')}\n",
            "  warn(msg)\n",
            "/anaconda/envs/codetf/lib/python3.10/site-packages/bitsandbytes/cuda_setup/main.py:149: UserWarning: WARNING: The following directories listed in your path were found to be non-existent: {PosixPath('Users/Paul.Brauckmann/mdl-ii/src/modeling/codet5p_770m_fine_tuning.ipynb')}\n",
            "  warn(msg)\n",
            "/anaconda/envs/codetf/lib/python3.10/site-packages/bitsandbytes/cuda_setup/main.py:149: UserWarning: WARNING: The following directories listed in your path were found to be non-existent: {PosixPath('module'), PosixPath('//matplotlib_inline.backend_inline')}\n",
            "  warn(msg)\n",
            "/anaconda/envs/codetf/lib/python3.10/site-packages/bitsandbytes/cuda_setup/main.py:149: UserWarning: Found duplicate ['libcudart.so', 'libcudart.so.11.0', 'libcudart.so.12.0'] files: {PosixPath('/usr/local/cuda/lib64/libcudart.so.11.0'), PosixPath('/usr/local/cuda/lib64/libcudart.so')}.. We'll flip a coin and try one of these, in order to fail forward.\n",
            "Either way, this might cause trouble in the future:\n",
            "If you get `CUDA error: invalid device function` errors, the above might be the cause and the solution is to make sure only one ['libcudart.so', 'libcudart.so.11.0', 'libcudart.so.12.0'] in the paths that we search based on your env.\n",
            "  warn(msg)\n",
            "/anaconda/envs/codetf/lib/python3.10/site-packages/bitsandbytes/cuda_setup/main.py:149: UserWarning: WARNING: Compute capability < 7.5 detected! Only slow 8-bit matmul is supported for your GPU!\n",
            "  warn(msg)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "===================================BUG REPORT===================================\n",
            "Welcome to bitsandbytes. For bug reports, please run\n",
            "\n",
            "python -m bitsandbytes\n",
            "\n",
            " and submit this information together with your error trace to: https://github.com/TimDettmers/bitsandbytes/issues\n",
            "================================================================================\n",
            "bin /anaconda/envs/codetf/lib/python3.10/site-packages/bitsandbytes/libbitsandbytes_cuda113_nocublaslt.so\n",
            "CUDA_SETUP: WARNING! libcudart.so not found in any environmental path. Searching in backup paths...\n",
            "CUDA SETUP: CUDA runtime path found: /usr/local/cuda/lib64/libcudart.so.11.0\n",
            "CUDA SETUP: Highest compute capability among GPUs detected: 3.7\n",
            "CUDA SETUP: Detected CUDA version 113\n",
            "CUDA SETUP: Loading binary /anaconda/envs/codetf/lib/python3.10/site-packages/bitsandbytes/libbitsandbytes_cuda113_nocublaslt.so...\n"
          ]
        }
      ],
      "source": [
        "from pathlib import Path\n",
        "\n",
        "from datasets import load_dataset\n",
        "from transformers import AutoModelForSeq2SeqLM, AutoTokenizer, TrainingArguments, Trainer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "gather": {
          "logged": 1688125156972
        }
      },
      "outputs": [],
      "source": [
        "root_dir = Path.cwd().parent"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "gather": {
          "logged": 1688125168720
        }
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Found cached dataset json (/mnt/batch/tasks/shared/LS_root/mounts/clusters/mdl/code/Users/Paul.Brauckmann/mdl-ii/src/data/cache/json/default-62e25f22c21bb7d6/0.0.0/e347ab1c932092252e717ff3f949105a4dd28b27e842dd53157d2f72e276c2e4)\n"
          ]
        }
      ],
      "source": [
        "datasets = load_dataset(\"json\", data_files={\n",
        "    \"train\": str(root_dir / \"data\" / \"train.jsonl\")\n",
        "}, cache_dir=root_dir / \"data\" / \"cache\", split=\"train\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "gather": {
          "logged": 1688125212394
        }
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                                                    \r"
          ]
        }
      ],
      "source": [
        "# datasets = load_dataset(\"code_x_glue_ct_code_to_text\", 'python', split=\"train\")\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"Salesforce/codet5p-770m-py\")\n",
        "\n",
        "def preprocess_function(examples):\n",
        "    source = [' '.join(ex) for ex in examples[\"code_tokens\"]]\n",
        "    target = [' '.join(ex) for ex in examples[\"docstring_tokens\"]]\n",
        "\n",
        "    model_inputs = tokenizer(source, max_length=320, padding=\"max_length\", truncation=True)\n",
        "    labels = tokenizer(target, max_length=128, padding=\"max_length\", truncation=True)\n",
        "\n",
        "    model_inputs[\"labels\"] = labels[\"input_ids\"].copy()\n",
        "    model_inputs[\"labels\"] = [\n",
        "        [(l if l != tokenizer.pad_token_id else -100) for l in label] for label in model_inputs[\"labels\"]\n",
        "    ]\n",
        "    return model_inputs\n",
        "\n",
        "train_data = datasets.map(\n",
        "    preprocess_function,\n",
        "    batched=True,\n",
        "    remove_columns=datasets.column_names,\n",
        "    num_proc=64,\n",
        "    load_from_cache_file=False,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "gather": {
          "logged": 1688125325370
        }
      },
      "outputs": [],
      "source": [
        "model = AutoModelForSeq2SeqLM.from_pretrained(\"Salesforce/codet5p-770m-py\")\n",
        "model.to(\"cuda\")\n",
        "\n",
        "training_args = TrainingArguments(\n",
        "    output_dir=root_dir / \"modeling\" / \"models\" / \"codet5p_770m_py\",\n",
        "    overwrite_output_dir=False,\n",
        "\n",
        "    do_train=True,\n",
        "    save_strategy='epoch',\n",
        "\n",
        "    num_train_epochs=2,\n",
        "    per_device_train_batch_size=4,\n",
        "    gradient_accumulation_steps=4,\n",
        "\n",
        "    learning_rate=5e-5,\n",
        "    weight_decay=0.05,\n",
        "    warmup_steps=200,\n",
        "\n",
        "    logging_dir=root_dir / \"modeling\" / \"models\" / \"codet5p_770m_py\",\n",
        "    logging_first_step=True,\n",
        "    logging_steps=100,\n",
        "    save_total_limit=1,\n",
        "\n",
        "    dataloader_drop_last=True,\n",
        "    dataloader_num_workers=4,\n",
        "\n",
        "    local_rank=-1,\n",
        "    deepspeed=None,\n",
        "    fp16=False,\n",
        ")\n",
        "\n",
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    train_dataset=train_data,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1688125379653
        }
      },
      "outputs": [],
      "source": [
        "trainer.train()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1688125379716
        }
      },
      "outputs": [],
      "source": [
        "trainer.save_model(root_dir / \"modeling\" / \"models\" / \"codet5p_770m_py\")"
      ]
    }
  ],
  "metadata": {
    "kernel_info": {
      "name": "codetf"
    },
    "kernelspec": {
      "display_name": "codetf",
      "language": "python",
      "name": "codetf"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.11"
    },
    "microsoft": {
      "host": {
        "AzureML": {
          "notebookHasBeenCompleted": true
        }
      },
      "ms_spell_check": {
        "ms_spell_check_language": "en"
      }
    },
    "nteract": {
      "version": "nteract-front-end@1.0.0"
    },
    "orig_nbformat": 4
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
